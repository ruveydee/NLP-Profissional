# NLP

## Pre-Trained Model (Bert) Fine Tuning for MultiClass 

We use the data about the news of Turkey and have the categories that belong to each news. 
These categories has occur 11 titles ('bilim_teknoloji', 'dunya', 'egitim', 'ekonomi', 'guncel','gundem', 'kultur_sanat', 'saglik', 'spor', 'turkiye', 'yasam') <br>
As seen, Bert model try to label to one of the  11 categories. 

<ul>
  <li>Using TPU Cores</li>
  <li>Reading Data</li>
  <li>Max Tesxt Lenght</li>
  <li>Pre-Trained Model Classification</li>
  <li>Converting data to dataset format</li>
  <li>Tokenization</li>
  <li>Create Optimazer and training with TPU cores</li>
  <li>Evaluation</li>
  <li>Saving and Loaded the model</li>
  <li>Predictiom</li>
</ul>  

 

